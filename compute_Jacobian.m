function [ J,numEvals ] = compute_Jacobian( x,func,options )
%COMPUTE_GRADIENT Summary of this function goes here
%   Detailed explanation goes here
defaultopt = struct(...
    'Algorithm','trust-region-reflective',...
    'DerivativeCheck','off',...
    'Diagnostics','off',...
    'DiffMaxChange',Inf,...
    'DiffMinChange',0,...
    'Display','final',...
    'FinDiffRelStep', [], ...
    'FinDiffType','forward',...
    'FunValCheck','off',...
    'InitDamping', 0.01, ...
    'Jacobian','off',...
    'JacobMult',[],... 
    'JacobPattern','sparse(ones(Jrows,Jcols))',...
    'MaxFunEvals',[],...
    'MaxIter',400,...
    'MaxPCGIter','max(1,floor(numberOfVariables/2))',...
    'OutputFcn',[],...
    'PlotFcns',[],...
    'PrecondBandWidth',Inf,...
    'ScaleProblem','none',...
    'TolFun',1e-6,...
    'TolPCG',0.1,...
    'TolX',1e-6,...
    'TypicalX','ones(numberOfVariables,1)');


Jac_pattern = optimget(options,'JacobPattern');
n = numel(x);
p = colamd(Jac_pattern)';
p = (n+1)*ones(n,1)-p;
group = color(Jac_pattern,p);
fval = func(x);
lb = -Inf(size(fval));
ub = Inf(size(fval));
[sizes.xRows,sizes.xCols] = size(x);


options.FinDiffType = optimget(options,'FinDiffType',defaultopt,'fast');
options.GradObj = optimget(options,'Jacobian',defaultopt,'fast');
options.GradConstr = 'off';
options.TypicalX = x;
options.FinDiffType = 'forward';
options.GradObj = 'off';
options.DiffMinChange = 0;
options.DiffMaxChange = Inf;

finDiffFlags.fwdFinDiff = strcmpi(options.FinDiffType,'forward'); % Check for forward fin-diff
finDiffFlags.scaleObjConstr = false; % No scaling
finDiffFlags.chkFunEval = false;     % Don't validate function values
finDiffFlags.chkComplexObj = false;  % Don't check whether objective function values are complex
finDiffFlags.isGrad = false;         % Compute Jacobian, not gradient
finDiffFlags.hasLBs = isfinite(lb);
finDiffFlags.hasUBs = isfinite(ub);

varargin = cell(0,0);
[J,numEvals] = sfdnls(x,fval,Jac_pattern,group,[],func,lb,ub,...
    options,sizes,finDiffFlags,varargin{:});
end

